# Projet Unix

Pour ce projet Unix, vous allez aligner des *reads* de s√©quences du Sars-Cov-2 d'√©chantillons de patients sur le g√©nome de r√©ference de Sars-Cov-2.

*Nous vous conseillons de noter les r√©ponses aux questions pos√©es dans un fichier texte. Vous reporterez ensuite ces r√©ponses dans un formulaire Google Form.*

## Pr√©sentation des donn√©es

Les fichiers de donn√©es au format `.fastq.gz` proviennent du projet [PRJNA673096](https://www.ncbi.nlm.nih.gov/sra/?term=PRJNA673096) sur SRA. Elles ont √©t√© produites par la technologie Illumina MiniSeq.

Les fichiers se trouvent sur le cluster dans le r√©pertoire 
```
/shared/projects/dubii2021/trainers/module1/project/fastq
```

Vous disposez chacun d'un jeu de fichiers diff√©rents √† analyser :

| Nom du r√©pertoire | stagiaire  |
|:-----------------:|:----------:|
| 00 | d√©mo |
| 01 | Harry |
| 02 | Marianne |
| 03 | Ga√´l |
| 04 | Sophie |
| 05 | Nicolas |
| 06 | Camille |
| 07 | Elodie |
| 08 | Emmanuelle |
| 09 | Alexandre |
| 10 | Domitille |
| 11 | Marika |
| 12 | Maria |
| 13 | Ga√´lle |
| 14 | Magali |
| 15 | Luc |
| 16 | Vichita |
| 17 | Natalia |
| 18 | Fabienne |
| 19 | Lucie |

Remarque : dans chaque r√©pertoire, le nombre de fichiers √† analyser varie entre 30 et 60 fichiers.

Depuis le Jupyter Hub, ouvrez un terminal Bash.


**Question 1** : Quel est le nombre exact de fichiers `.fastq.gz` que vous allez analyser ?

Indice : Vous utiliserez pour cela la commande `ls` combin√©e avec la commande `wc -l`.


**Question 2** : Quel est le volume de donn√©es total (en Go) des fichiers `.fastq.gz` que vous allez analyser ?


## Pr√©paration du r√©pertoire de travail

Dans votre r√©pertoire projet `/shared/projects/dubii2021/<login>` cr√©ez le r√©pertoire `dubii-unix-project` puis d√©placez-vous dans ce r√©pertoire.

Rappel : dans le chemin pr√©c√©dent, remplacez `<login>` par votre login sur le cluster.


**Question 3** : Quel est le chemin absolu de votre r√©pertoire courant ?


## Particularit√© des donn√©es propos√©es

Les donn√©es que vous allez analyser sont *paired-end*, c'est-√†-dire que les *reads* vont par paires, un sur chaque brin. Ces *reads* doivent donc √™tre align√©s ensemble. Concr√®tement, pour chaque √©chantillon, on a deux fichiers `.fastq.gz`, par exemple :
```
SRR13764654_1.fastq.gz
SRR13764654_2.fastq.gz
SRR13764655_1.fastq.gz
SRR13764655_2.fastq.gz
SRR13764656_1.fastq.gz
SRR13764656_2.fastq.gz
```
Ici, l'√©chantillon `SRR13764654` est associ√© aux fichiers `SRR13764654_1.fastq.gz` et `SRR13764654_2.fastq.gz`.

La bonne nouvelle est que logiciel `bowtie2` est capable d'aligner des *reads* *paired-end*. Il faut par contre lui fournir dans la m√™me commande les deux fichiers `.fastq.gz` concern√©s.


## Strat√©gie pour le *paired-end*

Comme l'a expliqu√© Julien, la bonne strat√©gie pour distribuer des analyses sur un cluster est celle du job array. Mais si le r√©pertoire de donn√©es contient 30 fichiers `.fastq.gz` il ne faudra pas cr√©er un job array de 30 jobs car en *paired-end*, les fichiers `.fastq.gz` sont associ√©s deux √† deux.

Dans l'exemple :
```
SRR13764654_1.fastq.gz
SRR13764654_2.fastq.gz
SRR13764655_1.fastq.gz
SRR13764655_2.fastq.gz
SRR13764656_1.fastq.gz
SRR13764656_2.fastq.gz
```
Il faudra un premier job pour traiter ensemble les fichiers `SRR13764654_1.fastq.gz` et `SRR13764654_2.fastq.gz`, un deuxi√®me pour les fichiers `SRR13764655_1.fastq.gz` et `SRR13764655_2.fastq.gz` et un troisi√®me pour les fichiers `SRR13764656_1.fastq.gz` et `SRR13764656_2.fastq.gz`.

Heureusement, les fichiers ont √©t√© nomm√©s intelligemment et on retrouve facilement les deux fichiers associ√©s au m√™me √©chantillon en ajoutant les extensions `_1.fastq.gz` et `_2.fastq.gz` au num√©ro d'√©chantillon.

L'astuce va donc √™tre de cr√©er un job array uniquement pour les fichiers `_1.fastq.gz` (puisque leurs bin√¥mes `_2.fastq.gz` sont toujours pr√©sents).

Par exemple pour aligner les *reads* des fichiers `.fastq.gz` du r√©pertoire `/shared/projects/dubii2021/trainers/module1/project/fastq/00`, on peut utiliser le script `map_reads.sh` suivant :

```
#!/bin/bash

#SBATCH --array=0-14
#SBATCH --cpus-per-task=10
#SBATCH --mem=1G

module load bowtie2/2.4.1 samtools/1.10

reference_index="/shared/projects/dubii2021/trainers/module1/project/genome/sars-cov-2"
file_path="/shared/projects/dubii2021/trainers/module1/project/fastq/00"

file_list=(${file_path}/*_1.fastq.gz)
file_id=$(basename -s _1.fastq.gz "${file_list[$SLURM_ARRAY_TASK_ID]}")

echo "Accession: ${file_id}"
echo "R1: ${file_path}/${file_id}_1.fastq.gz"
echo "R2: ${file_path}/${file_id}_2.fastq.gz"

srun -J "${file_id} bowtie2" bowtie2 --threads=${SLURM_CPUS_PER_TASK} -x "${reference_index}" -1 "${file_path}/${file_id}_1.fastq.gz" -2 "${file_path}/${file_id}_2.fastq.gz" -S "${file_id}.sam"

srun -J "${file_id} filter" samtools view -hbS -q 30 -o "${file_id}.filtered.bam" "${file_id}.sam"

srun -J "${file_id} sort" samtools sort -o "${file_id}.bam" "${file_id}.filtered.bam"

rm -f "${file_id}.sam" "${file_id}.filtered.bam"
```

Le r√©pertoire `/shared/projects/dubii2021/trainers/module1/project/fastq/00` contient 30 fichiers `.fastq.gz`, mais le job array n'est lanc√© que pour 15 jobs avec pour index 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13 et 14 :
```
#SBATCH --array=0-14
```

On ne r√©cup√®re que les fichiers `_1.fastq.gz` pour ensuite extraire le `file_id` du fichier :
```
file_list=(${file_path}/*_1.fastq.gz)
file_id=$(basename -s _1.fastq.gz "${file_list[$SLURM_ARRAY_TASK_ID]}")
```

Enfin, on remplace l'option `-U` de `bowtie2` utilis√©e pour r√©aliser des alignements en *single end* par les options `-1` et `-2` pour r√©aliser cette fois des alignements en *paired end* :
```
srun -J "${file_id} bowtie2" bowtie2 --threads=${SLURM_CPUS_PER_TASK} -x "${reference_index}" -1 "${file_path}/${file_id}_1.fastq.gz" -2 "${file_path}/${file_id}_2.fastq.gz" -S "${file_id}.sam"
```


## Faisons chauffer du CPU üöÄ

Si ce n'est pas d√©j√† fait, d√©placez vous dans votre r√©pertoire `/shared/projects/dubii2021/<login>/dubii-unix-project`.

Cr√©ez dans ce r√©pertoire le script `map_reads.sh` avec un √©diteur de texte (nano ou l'√©diteur de texte de Jupyter Lab). Faites attention lors du copier/coller car certaines lignes sont tr√®s longues.

Ne modifiez pas le script et lancez-le tel quel avec la commande :
```
sbatch map_reads.sh
```

**Question XX** : Quel est le job id de votre job ?


Suivez l'√©volution du calcul avec la commande
```
sacct --format=JobID%20,JobName%20,State,Start,Elapsed,CPUTime,NodeList -j <votre-job-id>
```
o√π bien s√ªr vous remplacez `<votre-job-id>` par votre job id.

V√©rifiez que toutes les tasks ont progressivement le status `COMPLETED`.

**Question XX** : Sur quel noeud du cluster s'est ex√©cut√© le premier job de votre job array (premi√®re ligne renvoy√©e par la commande `sacct` contenant `map_reads.sh`) ?


Pour la suite, faites un peu de m√©nage avec la commande :
```
rm -f SRR*.bam slurm*out
```

Attention, pas de retour arri√®re posible avec `rm` !


## Faisons chauffer du CPU encore une fois

Toujours depuis votre r√©pertoire `/shared/projects/dubii2021/<login>/dubii-unix-project`, copiez le script `map_reads.sh` en `map_reads_2.sh`.

Ouvrez le script `map_reads_2.sh` avec un √©diteur de texte (nano ou l'√©diteur de texte de Jupyter Lab). Modifiez ce script pour l'adapter aux donn√©es qui vous ont √©t√© attribu√©es. Vous ne devez a priori modifier que deux lignes dans le script.

Lancez ensuite votre script :
```
sbatch map_reads_2.sh
```

Suivez l'√©volution de votre script avec la commande `sacct`. Si votre script plante, essayez de comprendre ce qui se passe et de le corriger.

Conseil : si vous devez relancer plusieurs fois votre script, pensez √† faire du m√©nage √† chaque fois avec la commande 
```
rm -f SRR*.bam slurm*.out
```

Une fois que vous avez un job avec toutes les tasks `COMPLETED` : f√©licitation !


**Question XX** : Quel est le job id de votre job (lanc√© avec le script `map_reads_2.sh`) ?


**Question XX** : Combien de fichiers `.bam` avez-vous g√©n√©r√©s ?

V√©rifiez que ce nombre est coh√©rent avec le nombre de fichiers `.fast.gz` que vous avez √† analyser.


**Question XX** : Quel est le volume de donn√©es total (en Go) des fichiers `.bam` que vous avez g√©n√©r√©s ?


